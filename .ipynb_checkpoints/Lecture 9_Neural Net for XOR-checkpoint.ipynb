{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name= 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name= 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matul(X, W)))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * \n",
    "                       tf.log(1 - hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate= 0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACcuracy computaion\n",
    "# True if hypothesis > 0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype= tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), \n",
    "                                  dtype= tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    feed = {X: x_data, Y: y_data}\n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict= feed)\n",
    "        if step % 1000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict= feed), sess.run(W))\n",
    "    \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], \n",
    "                       feed_dict= feed)\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([2, 2]), name= 'weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name= 'bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([2, 1]), name= 'weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name= 'bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate= 0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype= tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype= tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7008579 [array([[ 0.23165324,  0.33121595],\n",
      "       [-1.8681543 , -0.20105003]], dtype=float32), array([[-0.13893163],\n",
      "       [-0.05648963]], dtype=float32)]\n",
      "1000 0.68013024 [array([[ 1.0416038 ,  0.33057508],\n",
      "       [-1.9208088 , -0.19237158]], dtype=float32), array([[-0.7457991 ],\n",
      "       [ 0.10382637]], dtype=float32)]\n",
      "2000 0.59043986 [array([[ 2.870031  ,  0.71909976],\n",
      "       [-2.8981435 , -0.55353355]], dtype=float32), array([[-2.2471306 ],\n",
      "       [ 0.87791485]], dtype=float32)]\n",
      "3000 0.24070293 [array([[ 4.542916 ,  2.828182 ],\n",
      "       [-4.386872 , -3.0641658]], dtype=float32), array([[-4.531925],\n",
      "       [ 4.216709]], dtype=float32)]\n",
      "4000 0.08501319 [array([[ 5.320479 ,  4.143279 ],\n",
      "       [-5.220641 , -4.4385576]], dtype=float32), array([[-6.263074],\n",
      "       [ 6.61318 ]], dtype=float32)]\n",
      "5000 0.047989488 [array([[ 5.7191277,  4.6982703],\n",
      "       [-5.6163177, -4.9958253]], dtype=float32), array([[-7.269992],\n",
      "       [ 7.777322]], dtype=float32)]\n",
      "6000 0.03285788 [array([[ 5.9736276,  5.0235925],\n",
      "       [-5.8609066, -5.3195715]], dtype=float32), array([[-7.954746],\n",
      "       [ 8.518028]], dtype=float32)]\n",
      "7000 0.024808891 [array([[ 6.1567473,  5.24767  ],\n",
      "       [-6.0346446, -5.541681 ]], dtype=float32), array([[-8.46916 ],\n",
      "       [ 9.057521]], dtype=float32)]\n",
      "8000 0.019858029 [array([[ 6.298209,  5.416233],\n",
      "       [-6.168083, -5.708428]], dtype=float32), array([[-8.879705],\n",
      "       [ 9.480754]], dtype=float32)]\n",
      "9000 0.016521104 [array([[ 6.412686 ,  5.550202 ],\n",
      "       [-6.2757735, -5.840813 ]], dtype=float32), array([[-9.220689],\n",
      "       [ 9.828573]], dtype=float32)]\n",
      "10000 0.014126315 [array([[ 6.5083933,  5.660734 ],\n",
      "       [-6.3656964, -5.949983 ]], dtype=float32), array([[-9.51198 ],\n",
      "       [10.123606]], dtype=float32)]\n",
      "\n",
      "Hypothesis:  [[0.01367241]\n",
      " [0.98209393]\n",
      " [0.98715043]\n",
      " [0.01166874]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    feed = {X: x_data, Y: y_data}\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict= feed)\n",
    "        if step % 1000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict= feed), sess.run([W1, W2]))\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], \n",
    "                       feed_dict= feed)\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 2])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([2, 10]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([10, 10]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.random_normal([10, 10]), name='weight3')\n",
    "b3 = tf.Variable(tf.random_normal([10]), name='bias3')\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.Variable(tf.random_normal([10, 1]), name='weight4')\n",
    "b4 = tf.Variable(tf.random_normal([1]), name='bias4')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer3, W4) + b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7103252\n",
      "1000 0.660403\n",
      "2000 0.15061581\n",
      "3000 0.016073566\n",
      "4000 0.006983882\n",
      "5000 0.004267903\n",
      "6000 0.0030160295\n",
      "7000 0.0023086958\n",
      "8000 0.0018585024\n",
      "9000 0.0015487603\n",
      "10000 0.0013236082\n",
      "\n",
      "Hypothesis:  [[0.00137505]\n",
      " [0.99865437]\n",
      " [0.9987581 ]\n",
      " [0.00132829]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    feed = {X: x_data, Y: y_data}\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict= feed)\n",
    "        if step % 1000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict= feed))\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], \n",
    "                       feed_dict= feed)\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
